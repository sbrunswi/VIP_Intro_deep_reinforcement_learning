{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66e7746a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "463c67bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorld:\n",
    "    \"\"\"Making a GridWorld object to make different grid size custom environments to mimic Fronze Lake\"\"\"\n",
    "\n",
    "    def __init__(self, size=4):\n",
    "        \"\"\"Setting up main parts of the Grid environment\n",
    "\n",
    "        Args:\n",
    "            size (4, optional): square grid side length. Defaults to 4.\n",
    "        \"\"\"\n",
    "        self.size = size  # - square grid size\n",
    "        self.nS = size * size  # - number of states\n",
    "        self.nA = 4  # - number of actions\n",
    "\n",
    "        self.UP, self.DOWN, self.LEFT, self.RIGHT = range(4)\n",
    "\n",
    "        self.goal = {self.nS - 1} # - goal is the last state index\n",
    "        self.holes = {5, 7, 11} # - holes are specific indices in the grid\n",
    "\n",
    "        self.P = self.build_transition_table()  # - the MDP\n",
    "\n",
    "    def build_transition_table(self):\n",
    "        \"\"\"Creating the transition function using a function and loops rather than writing a large dictionary by hand\"\"\"\n",
    "        P = {\n",
    "            s: {a: [] for a in range(self.nA)} for s in range(self.nS)\n",
    "        }  # ^ P[state][action] = []\n",
    "\n",
    "        for s in range(self.nS):  # * setting transitions for every state\n",
    "            row, col = divmod(\n",
    "                s, self.size\n",
    "            )  # ? divmod(a, b) -> (a // b, a % b), this maps index to grid position\n",
    "            #           state 6 in 4x4 grid\n",
    "            #           6 // 4 = 1  (row)\n",
    "            #           6 % 4  = 2  (col)\n",
    "\n",
    "            for a in range(self.nA):\n",
    "\n",
    "                if (\n",
    "                    s in self.goal or s in self.holes\n",
    "                ):  # * if state is already at goal or hole, loop back to itself with 0 reward\n",
    "\n",
    "                    P[s][a].append(\n",
    "                        (1.0, s, 0, True)\n",
    "                    )  # ? (1.0, s, 0, True) -> (probability, next_state, reward, done)\n",
    "\n",
    "                    continue\n",
    "                \n",
    "                new_row, new_col = (\n",
    "                    row,\n",
    "                    col,\n",
    "                )  # * assume we don't move to start, then update position based on action\n",
    "\n",
    "                # ! movement logic along with boundary checks\n",
    "                if (\n",
    "                    a == self.UP\n",
    "                ):  # ^ up one row, but max() prevents us from going out of bounds (negative row index)\n",
    "                    new_row = max(row - 1, 0)\n",
    "                elif (\n",
    "                    a == self.DOWN\n",
    "                ):  # ^ down one row, but min() prevents us from going out of bounds (exceeding row index)\n",
    "                    new_row = min(row + 1, self.size - 1)\n",
    "                elif (\n",
    "                    a == self.LEFT\n",
    "                ):  # ^ left one column, but max() prevents us from going out of bounds (negative column index)\n",
    "                    new_col = max(col - 1, 0)\n",
    "                elif (\n",
    "                    a == self.RIGHT\n",
    "                ):  # ^ right one column, but min() prevents us from going out of bounds (exceeding column index)\n",
    "                    new_col = min(col + 1, self.size - 1)\n",
    "\n",
    "                ns = (\n",
    "                    new_row * self.size + new_col\n",
    "                )  # - ns -> new state index after movement\n",
    "                # ? (1,2) → 1*4 + 2 = 6 -> math for ns\n",
    "\n",
    "                reward = -0.01  # - time cost\n",
    "                done = False  # - default done is False, is True when we hit a hole or the goal\n",
    "\n",
    "                if (\n",
    "                    ns in self.holes\n",
    "                ):  # * hole is bad (reward = -1) and ends episode (done = True)\n",
    "                    reward = -1\n",
    "                    done = True\n",
    "\n",
    "                if (\n",
    "                    ns in self.goal\n",
    "                ):  # * goal is good (reward = 1) and ends episode (done = True)\n",
    "                    reward = 1\n",
    "                    done = True\n",
    "\n",
    "                P[s][a].append((1.0, ns, reward, done))  # ? P(s′∣s,a) = 1\n",
    "\n",
    "        return P  # * returns the full transition table for the MDP\n",
    "        # ^ this transition function is deterministic\n",
    "        # ^ each action has 1.0 probability of leading to the next state\n",
    "        # ^ not slippery, yet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1699d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(env, gamma=0.99, theta=1e-6):\n",
    "    \"\"\"Value Iteration algorithm to solve the MDP\n",
    "\n",
    "    Args:\n",
    "        env (GridWorld): The GridWorld environment instance\n",
    "        gamma (float, optional): Discount factor. Defaults to 0.99.\n",
    "        theta (float, optional): Convergence threshold. Defaults to 1e-6.\n",
    "\n",
    "    Returns:\n",
    "        V (numpy array): Optimal value function\n",
    "    \"\"\"\n",
    "\n",
    "    V = np.zeros(env.nS)  # - initialize value function\n",
    "\n",
    "    while True:\n",
    "        delta = 0  # - to track max change in value function\n",
    "        \n",
    "        for s in range(env.nS):  # * for each state\n",
    "            values = []\n",
    "\n",
    "            for a in range(env.nA):  # * for each action\n",
    "                total = 0\n",
    "                \n",
    "                for p, ns, r, _ in env.P[s][\n",
    "                    a\n",
    "                ]:  # * for each possible outcome of action a in state s\n",
    "                    total += p * (\n",
    "                        r + gamma * V[ns]\n",
    "                    )  # - Bellman update for value iteration\n",
    "                    # ? Bellman equation -> r + γV(s′)\n",
    "                values.append(total)  # * store the value for action a\n",
    "            \n",
    "            best = max(values)  # * best action value\n",
    "            delta = max(delta, abs(V[s] - best))  # * update delta with max change\n",
    "            V[s] = best  # * update value function for state s\n",
    "        \n",
    "        if delta < theta:  # * check for convergence\n",
    "            break\n",
    "    \n",
    "    return V  # * return the optimal value function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bab166bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_policy(env, V, gamma=0.99):\n",
    "    \"\"\"Extract the optimal policy from the optimal value function\n",
    "    \n",
    "    Args:\n",
    "        env (GridWorld): The GridWorld environment instance\n",
    "        V (numpy array): Optimal value function\n",
    "        gamma (float, optional): Discount factor. Defaults to 0.99.\n",
    "    \n",
    "    Returns:\n",
    "        policy (numpy array): Optimal policy\n",
    "    \"\"\"\n",
    "\n",
    "    policy = np.zeros(env.nS, dtype=int)\n",
    "\n",
    "    for s in range(env.nS):  # * for each state\n",
    "        action_values = []\n",
    "\n",
    "        for a in range(env.nA):  # * for each action\n",
    "            total = 0\n",
    "\n",
    "            for p, ns, r, _ in env.P[s][\n",
    "                a\n",
    "            ]:  # * for each possible outcome of action a in state s\n",
    "                total += p * (r + gamma * V[ns])\n",
    "            action_values.append(total)\n",
    "\n",
    "        policy[s] = np.argmax(\n",
    "            action_values\n",
    "        )  # * returns the index for which action has the highest value for a state\n",
    "    \n",
    "    return policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecd7e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_policy(env, policy):\n",
    "    \"\"\"Visualization of the GridWorld environment\n",
    "    \n",
    "    Args:\n",
    "        env (GridWorld): The GridWorld environment instance\n",
    "        policy (numpy array): Optimal policy\n",
    "    \"\"\"\n",
    "    arrows = [\"↑\", \"↓\", \"←\", \"→\"]\n",
    "    \n",
    "    for s in range(env.nS):\n",
    "        if s in env.holes:\n",
    "            print(\" H \", end=\"\")\n",
    "        elif s in env.goal:\n",
    "            print(\" G \", end=\"\")\n",
    "        else:\n",
    "            print(f\" {arrows[policy[s]]} \", end=\"\")\n",
    "        \n",
    "        if (s + 1) % env.size == 0:\n",
    "            print()\n",
    "\n",
    "\n",
    "def render_policy_image(env, policy):\n",
    "    \"\"\"Render the policy as a graphical image using matplotlib.\"\"\"\n",
    "    \n",
    "    size = env.size\n",
    "    fig, ax = plt.subplots(figsize=(size, size))\n",
    "    ax.set_xlim(0, size)\n",
    "    ax.set_ylim(0, size)\n",
    "    ax.set_xticks(np.arange(0, size+1, 1))\n",
    "    ax.set_yticks(np.arange(0, size+1, 1))\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.grid(True)\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "    # Draw holes and goal\n",
    "    for s in range(env.nS):\n",
    "        row, col = divmod(s, size)\n",
    "        if s in env.holes:\n",
    "            ax.add_patch(plt.Rectangle((col, size-1-row), 1, 1, color='black'))\n",
    "        elif s in env.goal:\n",
    "            ax.add_patch(plt.Rectangle((col, size-1-row), 1, 1, color='gold'))\n",
    "    \n",
    "    # Draw arrows for policy\n",
    "    arrow_dict = {\n",
    "        0: (0, 0.2, 0, 0.2),   # UP\n",
    "        1: (0, -0.2, 0, -0.2), # DOWN\n",
    "        2: (-0.2, 0, -0.2, 0), # LEFT\n",
    "        3: (0.2, 0, 0.2, 0),   # RIGHT\n",
    "    }\n",
    "    for s in range(env.nS):\n",
    "        if s in env.holes or s in env.goal:\n",
    "            continue\n",
    "        row, col = divmod(s, size)\n",
    "        a = policy[s]\n",
    "        dx1, dy1, dx2, dy2 = arrow_dict[a]\n",
    "        ax.arrow(col+0.5, size-1-row+0.5, dx1, dy1, head_width=0.2, head_length=0.2, fc='blue', ec='blue')\n",
    "    \n",
    "    # Draw grid lines\n",
    "    for i in range(size+1):\n",
    "        ax.axhline(i, color='gray', linewidth=0.5)\n",
    "        ax.axvline(i, color='gray', linewidth=0.5)\n",
    "    \n",
    "    # Legend\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [\n",
    "        Patch(facecolor='black', edgecolor='black', label='Hole'),\n",
    "        Patch(facecolor='gold', edgecolor='gold', label='Goal'),\n",
    "        Patch(facecolor='white', edgecolor='black', label='Normal State')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    \n",
    "    # Show plot\n",
    "    plt.title('Optimal Policy')\n",
    "    plt.tight_layout(rect=[0, 0, 1, 1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a3744c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value function:\n",
      " [[0.9019801  0.92119202 0.940598   0.92119202]\n",
      " [0.92119202 0.         0.9602     0.        ]\n",
      " [0.940598   0.9602     0.98       0.        ]\n",
      " [0.9602     0.98       1.         0.        ]]\n",
      "\n",
      "Optimal policy:\n",
      " ↓  →  ↓  ← \n",
      " ↓  H  ↓  H \n",
      " ↓  ↓  ↓  H \n",
      " →  →  →  G \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    env = GridWorld(size=4)\n",
    "    \n",
    "    V = value_iteration(env)\n",
    "    policy = extract_policy(env, V)\n",
    "    \n",
    "    print(\"Value function:\\n\", V.reshape(env.size, env.size)) # * reshape value function to match grid layout for better visualization\n",
    "    print(\"\\nOptimal policy:\") # * print the optimal policy in a grid format using arrows to indicate actions\n",
    "    \n",
    "    render_policy(env, policy)\n",
    "    render_policy_image(env, policy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
